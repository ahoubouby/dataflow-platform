# ============================================
# DataFlow Platform API - Application Configuration
# ============================================
# This is the APPLICATION module - contains all cluster and Cassandra config

# ============================================
# API CONFIGURATION
# ============================================
dataflow {
  api {
    # HTTP server configuration
    host = "0.0.0.0"
    host = ${?API_HOST}

    port = 8080
    port = ${?API_PORT}

    # Request timeout
    request-timeout = 30s

    # WebSocket configuration
    websocket {
      update-interval = 2s
    }
  }
}

# ============================================
# PEKKO CONFIGURATION
# ============================================
pekko {
  loglevel = "INFO"
  loglevel = ${?PEKKO_LOG_LEVEL}

  log-config-on-start = off
  log-dead-letters = 10
  log-dead-letters-during-shutdown = off

  # ============================================
  # ACTOR SYSTEM
  # ============================================
  actor {
    provider = cluster

    warn-about-java-serializer-usage = on
    allow-java-serialization = off

    serializers {
      jackson-json = "org.apache.pekko.serialization.jackson.JacksonJsonSerializer"
      jackson-cbor = "org.apache.pekko.serialization.jackson.JacksonCborSerializer"
    }

    serialization-bindings {
      "com.dataflow.serialization.CborSerializable" = jackson-cbor
    }

    debug {
      receive = off
      lifecycle = off
      unhandled = on
    }
  }

  # ============================================
  # REMOTE / CLUSTER COMMUNICATION
  # ============================================
  remote.artery {
    enabled = on
    transport = tcp

    canonical {
      hostname = "127.0.0.1"
      hostname = ${?PEKKO_HOST}
      port = 2551
      port = ${?PEKKO_PORT}
    }

    advanced {
      maximum-frame-size = 512 KiB
      outbound-message-queue-size = 3072

      compression {
        actor-refs.max = 256
        manifests.max = 256
      }
    }
  }

  # ============================================
  # CLUSTER CONFIGURATION
  # ============================================
  cluster {
    seed-nodes = ["pekko://DataFlowSystem@127.0.0.1:2551"]
    seed-nodes = ${?PEKKO_SEED_NODES}

    # Downing provider
    downing-provider-class = "org.apache.pekko.cluster.sbr.SplitBrainResolverProvider"

    # Sharding configuration
    sharding {
      number-of-shards = 100

      passivation {
        default-idle-strategy.idle-timeout = 5m
      }
    }
  }

  # ============================================
  # PERSISTENCE CONFIGURATION
  # ============================================
  persistence {
    journal {
      plugin = "pekko.persistence.cassandra.journal"
      auto-start-journals = ["pekko.persistence.cassandra.journal"]
    }

    snapshot-store {
      plugin = "pekko.persistence.cassandra.snapshot"
      auto-start-snapshot-stores = ["pekko.persistence.cassandra.snapshot"]
    }

    # Cassandra plugin configuration
    cassandra {
      journal {
        keyspace = "dataflow_journal"
        table = "messages"

        # Replication strategy
        replication-strategy = "SimpleStrategy"
        replication-factor = 1

        # Consistency levels
        write-consistency = "QUORUM"
        read-consistency = "QUORUM"

        # Auto-creation (disable in production)
        keyspace-autocreate = true
        keyspace-autocreate = ${?CASSANDRA_KEYSPACE_AUTOCREATE}
        tables-autocreate = true
        tables-autocreate = ${?CASSANDRA_TABLES_AUTOCREATE}

        # Event tagging for projections
        event-processor {
          tag-write-parallelism = 4
        }
      }

      snapshot {
        keyspace = "dataflow_snapshot"
        table = "snapshots"

        # Replication strategy
        replication-strategy = "SimpleStrategy"
        replication-factor = 1

        # Consistency levels
        write-consistency = "ONE"
        read-consistency = "ONE"

        # Auto-creation (disable in production)
        keyspace-autocreate = true
        keyspace-autocreate = ${?CASSANDRA_KEYSPACE_AUTOCREATE}
        tables-autocreate = true
        tables-autocreate = ${?CASSANDRA_TABLES_AUTOCREATE}
      }

      # Query configuration (for CassandraReadJournal)
      query {
        refresh-interval = 3s
        max-buffer-size = 500
        max-result-size = 50000
      }

      # Reference to Datastax driver config
      datastax-java-driver-config = "datastax-java-driver"
    }

    # At-least-once delivery settings
    at-least-once-delivery {
      redeliver-interval = 5s
      redelivery-burst-limit = 10000
      warn-after-number-of-unconfirmed-attempts = 5
      max-unconfirmed-messages = 100000
    }

    # Recovery settings
    recovery {
      max-events-per-batch = 1000
    }
  }

  # ============================================
  # HTTP CONFIGURATION
  # ============================================
  http {
    server {
      request-timeout = ${dataflow.api.request-timeout}
      idle-timeout = 60s

      # WebSocket settings
      websocket {
        periodic-keep-alive-max-idle = 10s
      }

      # Parsing settings
      parsing {
        max-content-length = 8m
        max-uri-length = 2k
      }
    }

    client {
      connecting-timeout = 10s
      idle-timeout = 60s
    }

    host-connection-pool {
      max-connections = 4
      max-open-requests = 32
      idle-timeout = 30s
    }
  }

  # ============================================
  # COORDINATED SHUTDOWN
  # ============================================
  coordinated-shutdown {
    default-phase-timeout = 10s

    phases {
      before-service-unbind {
        timeout = 30s
      }
    }
  }
}

# ============================================
# DATASTAX JAVA DRIVER CONFIGURATION
# ============================================
datastax-java-driver {
  basic {
    # Cassandra contact points
    contact-points = ["127.0.0.1:9042"]
    contact-points = ${?CASSANDRA_CONTACT_POINTS}

    # Local datacenter
    load-balancing-policy.local-datacenter = "datacenter1"

    # Session name
    session-name = "dataflow-persistence"

    # Request timeout (allow time for Cassandra to start)
    request {
      timeout = 10 seconds
    }
  }

  advanced {
    # Connection settings
    connection {
      init-query-timeout = 10 seconds
      set-keyspace-timeout = 10 seconds
      max-requests-per-connection = 1024
      pool.local.size = 1
    }

    # Reconnection policy (exponential backoff)
    reconnection-policy {
      class = ExponentialReconnectionPolicy
      base-delay = 1 second
      max-delay = 60 seconds
    }

    # Retry policy for failed queries
    retry-policy {
      class = DefaultRetryPolicy
    }

    # Authentication (if needed)
    # auth-provider {
    #   class = PlainTextAuthProvider
    #   username = "cassandra"
    #   password = "cassandra"
    # }
  }
}

# ============================================
# PEKKO MANAGEMENT CONFIGURATION
# ============================================
pekko.management {
  http {
    hostname = "127.0.0.1"
    hostname = ${?MANAGEMENT_HOST}
    port = 8558
    port = ${?MANAGEMENT_PORT}
  }

  cluster.bootstrap {
    contact-point-discovery {
      service-name = "dataflow-api"
      discovery-method = config
      required-contact-point-nr = 1
    }
  }
}

# ============================================
# ADDITIONAL INCLUDES
# ============================================
# Include cluster-specific configuration
include "cluster.conf"

# Include Kamon metrics configuration
include "kamon-local.conf"

# Include environment-specific configuration
# Use -Dconfig.resource=application-prod.conf to override
