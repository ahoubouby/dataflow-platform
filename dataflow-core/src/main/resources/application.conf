# ============================================
# DataFlow Platform - Application Configuration
# ============================================
# Apache Pekko configuration for event-sourced distributed pipelines

# ============================================
# ACTOR SYSTEM
# ============================================
dataflow {
  # Application name
  system-name = "DataflowPlatform"

  # HTTP API settings (for future API module)
  api {
    host = "0.0.0.0"
    host = ${?DATAFLOW_API_HOST}
    port = 8080
    port = ${?DATAFLOW_API_PORT}
  }

  # Pipeline settings
  pipeline {
    # Default batch size for ingestion
    default-batch-size = 1000

    # Maximum concurrent pipelines per node
    max-pipelines = 100

    # Checkpoint frequency
    checkpoint-interval = 10 seconds
  }
}

pekko {
  # Logging configuration
  loglevel = "INFO"
  loglevel = ${?PEKKO_LOG_LEVEL}

  # Log configuration on startup
  log-config-on-start = off

  # Log dead letters
  log-dead-letters = 10
  log-dead-letters-during-shutdown = off

  # Actor system logging
  actor {
    debug {
      # Enable logging of all messages sent to an actor
      receive = off

      # Enable logging of actor lifecycle changes
      lifecycle = off

      # Enable logging of unhandled messages
      unhandled = on
    }

    # Warn about java serialization
    warn-about-java-serializer-usage = on
    allow-java-serialization = off

    # Serialization configuration
    serializers {
      jackson-json = "org.apache.pekko.serialization.jackson.JacksonJsonSerializer"
      jackson-cbor = "org.apache.pekko.serialization.jackson.JacksonCborSerializer"
    }

    serialization-bindings {
      "com.dataflow.serialization.CborSerializable" = jackson-cbor
    }

    # Provider for clustering
    provider = cluster
  }

  # ============================================
  # REMOTE / CLUSTER COMMUNICATION
  # ============================================
  remote {
    artery {
      enabled = on
      transport = tcp

      canonical {
        hostname = "127.0.0.1"
        hostname = ${?PEKKO_REMOTE_HOST}
        port = 2551
        port = ${?PEKKO_REMOTE_PORT}
      }

      # Advanced tuning
      advanced {
        # Maximum size of messages that can be sent
        maximum-frame-size = 512 KiB

        # Buffer size for outbound messages
        outbound-message-queue-size = 3072

        # Compression settings
        compression {
          actor-refs {
            max = 256
          }
          manifests {
            max = 256
          }
        }
      }
    }
  }

  # ============================================
  # PERSISTENCE CONFIGURATION
  # ============================================
  persistence {
    # Journal plugin
    journal {
      plugin = "pekko.persistence.cassandra.journal"

      # Auto-start journal on system startup
      auto-start-journals = ["pekko.persistence.cassandra.journal"]
    }

    # Snapshot store plugin
    snapshot-store {
      plugin = "pekko.persistence.cassandra.snapshot"

      # Auto-start snapshot store on system startup
      auto-start-snapshot-stores = ["pekko.persistence.cassandra.snapshot"]
    }

    # Event adapter configuration
    # Used for event versioning and migration
    # event-adapters {
    #   pipeline-tagger = "com.dataflow.adapters.PipelineEventTagger"
    # }

    # event-adapter-bindings {
    #   "com.dataflow.domain.events.PipelineEvent" = pipeline-tagger
    # }

    # At-least-once delivery settings
    at-least-once-delivery {
      redeliver-interval = 5s
      redelivery-burst-limit = 10000
      warn-after-number-of-unconfirmed-attempts = 5
      max-unconfirmed-messages = 100000
    }

    # Failure recovery settings
    recovery {
      # Maximum number of events to replay per batch
      max-events-per-batch = 1000
    }
  }

  # ============================================
  # CASSANDRA PLUGIN CONFIGURATION
  # ============================================
  persistence.cassandra {
    # Journal configuration
    journal {
      # Keyspace name
      keyspace = "dataflow_journal"

      # Table name
      table = "messages"

      # Replication strategy
      replication-strategy = "SimpleStrategy"
      replication-factor = 1

      # Write consistency level
      write-consistency = "QUORUM"

      # Read consistency level
      read-consistency = "QUORUM"

      # Enable events by tag for projections
      event-processor {
        # Number of tag writers
        # Increase for better throughput with projections
        tag-write-parallelism = 4
      }
    }

    # Snapshot configuration
    snapshot {
      # Keyspace name
      keyspace = "dataflow_snapshot"

      # Table name
      table = "snapshots"

      # Replication strategy
      replication-strategy = "SimpleStrategy"
      replication-factor = 1

      # Write consistency level
      write-consistency = "ONE"

      # Read consistency level
      read-consistency = "ONE"
    }

    # Query configuration
    query {
      # Refresh interval for live queries
      refresh-interval = 3s

      # Maximum buffer size
      max-buffer-size = 500

      # Maximum result size for queries
      max-result-size = 50000
    }

    # Session settings
    session-provider = "pekko.persistence.cassandra.ConfigSessionProvider"

    # Cassandra connection settings
    session {
      # Contact points
      contact-points = ["127.0.0.1:9042"]
      contact-points = ${?CASSANDRA_CONTACT_POINTS}

      # Local datacenter
      local-datacenter = "datacenter1"
      local-datacenter = ${?CASSANDRA_LOCAL_DC}

      # Credentials (if authentication is enabled)
      # authentication {
      #   username = "cassandra"
      #   username = ${?CASSANDRA_USERNAME}
      #   password = "cassandra"
      #   password = ${?CASSANDRA_PASSWORD}
      # }

      # Connection settings
      connection {
        # Connection timeout
        connect-timeout = 5s

        # Request timeout
        request-timeout = 10s

        # Pool settings
        pool {
          # Number of connections per host
          local.size = 2
        }
      }
    }

    # Keyspace auto-creation (disable in production)
    keyspace-autocreate = true
    keyspace-autocreate = ${?CASSANDRA_KEYSPACE_AUTOCREATE}

    # Table auto-creation (disable in production)
    tables-autocreate = true
    tables-autocreate = ${?CASSANDRA_TABLES_AUTOCREATE}
  }

  # ============================================
  # PROJECTION CONFIGURATION (for future use)
  # ============================================
  projection {
    # Cassandra offset store
    cassandra {
      offset-store {
        keyspace = "dataflow_projections"
        table = "offsets"
      }
    }

    # Restart backoff settings
    restart-backoff {
      min-backoff = 3s
      max-backoff = 30s
      random-factor = 0.2
    }

    # Recovery strategy
    recovery-strategy {
      strategy = fail
      retries = 5
      retry-delay = 1s
    }
  }

  # ============================================
  # COORDINATED SHUTDOWN
  # ============================================
  coordinated-shutdown {
    # Timeout for each shutdown phase
    default-phase-timeout = 10s

    # Phases configuration
    phases {
      # Custom phase for graceful pipeline shutdown
      before-service-unbind {
        timeout = 30s
        depends-on = [cluster-sharding-shutdown-region]
      }
    }
  }

  # ============================================
  # MANAGEMENT (for Pekko Management in future)
  # ============================================
  # management {
  #   http {
  #     hostname = "0.0.0.0"
  #     port = 8558
  #
  #     route-providers-read-only = false
  #   }
  #
  #   cluster {
  #     bootstrap {
  #       contact-point-discovery {
  #         service-name = "dataflow-platform"
  #         discovery-method = config
  #       }
  #     }
  #   }
  #
  #   health-checks {
  #     readiness-checks {
  #       cluster-membership = "org.apache.pekko.management.cluster.scaladsl.ClusterMembershipCheck"
  #     }
  #
  #     liveness-checks {
  #       cluster-membership = "org.apache.pekko.management.cluster.scaladsl.ClusterMembershipCheck"
  #     }
  #   }
  # }
}

# ============================================
# PEKKO HTTP CONFIGURATION (for future API module)
# ============================================
pekko.http {
  server {
    # Server listening interface
    interface = "0.0.0.0"

    # Request timeout
    request-timeout = 20s

    # Idle timeout
    idle-timeout = 60s

    # Maximum connections
    max-connections = 1024

    # Backlog size
    backlog = 100

    # Parsing settings
    parsing {
      max-content-length = 8m
      max-uri-length = 2k
    }
  }

  client {
    # Connection timeout
    connecting-timeout = 10s

    # Idle timeout
    idle-timeout = 60s
  }

  host-connection-pool {
    # Maximum connections per host
    max-connections = 4

    # Maximum open requests
    max-open-requests = 32

    # Idle timeout
    idle-timeout = 30s
  }
}

# ============================================
# LOGGING BACKEND (Logback)
# ============================================
# Additional configuration in logback.xml



# ============================================
# ENVIRONMENT-SPECIFIC OVERRIDES
# ============================================
# Override any setting using environment variables:
#
# PEKKO_LOG_LEVEL=DEBUG
# PEKKO_REMOTE_HOST=192.168.1.100
# PEKKO_REMOTE_PORT=2551
# CASSANDRA_CONTACT_POINTS=["cassandra1:9042","cassandra2:9042"]
# CASSANDRA_KEYSPACE_AUTOCREATE=false
# CASSANDRA_TABLES_AUTOCREATE=false
#
# Or provide application-prod.conf, application-dev.conf, etc.
# and use: -Dconfig.resource=application-prod.conf

# ============================================
# DEVELOPMENT MODE
# ============================================
# For local development, include development.conf:
# include "development"

# ============================================
# PRODUCTION MODE
# ============================================
# For production, include production.conf:
# include "production"
include "kamon-local.conf"
include "development.conf"
include "cluster.conf"
