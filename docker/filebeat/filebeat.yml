# ==========================================
# Filebeat Configuration for DataFlow Platform
# ==========================================
# Ships logs from application to Elasticsearch/Logstash

# ==========================================
# Filebeat Inputs
# ==========================================
filebeat.inputs:
  # DataFlow Application Logs (Plain Text Format)
  - type: log
    enabled: true
    paths:
      - /var/log/dataflow/*.log
    fields:
      service: dataflow-platform
      log_type: application
    fields_under_root: true
    # Multiline pattern for stack traces
    # Lines starting with date are new log entries
    # Lines NOT starting with date are continuations (stack traces)
    multiline.type: pattern
    multiline.pattern: '^[0-9]{4}-[0-9]{2}-[0-9]{2}'
    multiline.negate: true
    multiline.match: after
    # Remove JSON decoder (logs are plain text, not JSON)
    # json.keys_under_root: false
    # json.add_error_key: true

  # Docker Container Logs (optional)
  - type: container
    enabled: false
    paths:
      - '/var/lib/docker/containers/*/*.log'
    processors:
      - add_docker_metadata:
          host: "unix:///var/run/docker.sock"

# ==========================================
# Filebeat Modules
# ==========================================
filebeat.config.modules:
  path: ${path.config}/modules.d/*.yml
  reload.enabled: false

# ==========================================
# Processors
# ==========================================
processors:
  - add_host_metadata:
      when.not.contains.tags: forwarded
  - add_cloud_metadata: ~
  - add_docker_metadata: ~
  - add_kubernetes_metadata: ~
  - add_fields:
      target: ''
      fields:
        environment: development
        platform: dataflow

# ==========================================
# Output Configuration
# ==========================================

# Output to Logstash (recommended for production)
output.logstash:
  enabled: true
  hosts: ["${LOGSTASH_HOSTS:logstash:5044}"]
  worker: 2
  compression_level: 3
  loadbalance: true

# Output to Elasticsearch (alternative - direct)
# Uncomment to send directly to Elasticsearch instead of Logstash
# output.elasticsearch:
#   enabled: false
#   hosts: ["${ELASTICSEARCH_HOSTS:http://elasticsearch:9200}"]
#   indices:
#     - index: "dataflow-logs-%{+yyyy.MM.dd}"
#       when.equals:
#         fields.log_type: "application"
#     - index: "dataflow-container-logs-%{+yyyy.MM.dd}"
#       when.equals:
#         type: "container"
#   pipeline: ""

# ==========================================
# Logging Configuration
# ==========================================
logging.level: info
logging.to_files: true
logging.files:
  path: /var/log/filebeat
  name: filebeat
  keepfiles: 7
  permissions: 0644

# ==========================================
# Monitoring
# ==========================================
monitoring.enabled: false
# monitoring.elasticsearch:
#   hosts: ["${ELASTICSEARCH_HOSTS:http://elasticsearch:9200}"]

# ==========================================
# Setup Configuration
# ==========================================
setup.ilm.enabled: false
setup.template.enabled: true
setup.template.name: "dataflow-logs"
setup.template.pattern: "dataflow-logs-*"

# Kibana configuration for dashboards
setup.kibana:
  host: "kibana:5601"

# ==========================================
# Queue Configuration
# ==========================================
queue.mem:
  events: 4096
  flush.min_events: 512
  flush.timeout: 5s
